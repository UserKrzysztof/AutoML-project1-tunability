{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "DATA = []\n",
    "for file in os.listdir(data_path):\n",
    "    DATA.append(pd.read_csv(os.path.join(data_path,file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        5000 non-null   int64 \n",
      " 1   job        5000 non-null   object\n",
      " 2   marital    5000 non-null   object\n",
      " 3   education  5000 non-null   object\n",
      " 4   default    5000 non-null   object\n",
      " 5   balance    5000 non-null   int64 \n",
      " 6   housing    5000 non-null   object\n",
      " 7   loan       5000 non-null   object\n",
      " 8   contact    5000 non-null   object\n",
      " 9   day        5000 non-null   int64 \n",
      " 10  month      5000 non-null   object\n",
      " 11  duration   5000 non-null   int64 \n",
      " 12  campaign   5000 non-null   int64 \n",
      " 13  pdays      5000 non-null   int64 \n",
      " 14  previous   5000 non-null   int64 \n",
      " 15  poutcome   5000 non-null   object\n",
      " 16  y          5000 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 664.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Unnamed: 0                         5000 non-null   int64  \n",
      " 1   id                                 5000 non-null   int64  \n",
      " 2   Gender                             5000 non-null   object \n",
      " 3   Customer Type                      5000 non-null   object \n",
      " 4   Age                                5000 non-null   int64  \n",
      " 5   Type of Travel                     5000 non-null   object \n",
      " 6   Class                              5000 non-null   object \n",
      " 7   Flight Distance                    5000 non-null   int64  \n",
      " 8   Inflight wifi service              5000 non-null   int64  \n",
      " 9   Departure/Arrival time convenient  5000 non-null   int64  \n",
      " 10  Ease of Online booking             5000 non-null   int64  \n",
      " 11  Gate location                      5000 non-null   int64  \n",
      " 12  Food and drink                     5000 non-null   int64  \n",
      " 13  Online boarding                    5000 non-null   int64  \n",
      " 14  Seat comfort                       5000 non-null   int64  \n",
      " 15  Inflight entertainment             5000 non-null   int64  \n",
      " 16  On-board service                   5000 non-null   int64  \n",
      " 17  Leg room service                   5000 non-null   int64  \n",
      " 18  Baggage handling                   5000 non-null   int64  \n",
      " 19  Checkin service                    5000 non-null   int64  \n",
      " 20  Inflight service                   5000 non-null   int64  \n",
      " 21  Cleanliness                        5000 non-null   int64  \n",
      " 22  Departure Delay in Minutes         5000 non-null   int64  \n",
      " 23  Arrival Delay in Minutes           4981 non-null   float64\n",
      " 24  satisfaction                       5000 non-null   object \n",
      "dtypes: float64(1), int64(19), object(5)\n",
      "memory usage: 976.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   season                5000 non-null   object \n",
      " 1   cap-diameter          5000 non-null   float64\n",
      " 2   cap-shape             5000 non-null   object \n",
      " 3   cap-surface           3839 non-null   object \n",
      " 4   cap-color             5000 non-null   object \n",
      " 5   does-bruise-or-bleed  5000 non-null   object \n",
      " 6   gill-attachment       4215 non-null   object \n",
      " 7   gill-spacing          2992 non-null   object \n",
      " 8   gill-color            5000 non-null   object \n",
      " 9   stem-height           5000 non-null   float64\n",
      " 10  stem-width            5000 non-null   float64\n",
      " 11  stem-root             747 non-null    object \n",
      " 12  stem-surface          1934 non-null   object \n",
      " 13  stem-color            5000 non-null   object \n",
      " 14  veil-type             258 non-null    object \n",
      " 15  veil-color            578 non-null    object \n",
      " 16  has-ring              5000 non-null   object \n",
      " 17  ring-type             4784 non-null   object \n",
      " 18  spore-print-color     513 non-null    object \n",
      " 19  habitat               5000 non-null   object \n",
      " 20  class                 5000 non-null   object \n",
      "dtypes: float64(3), object(18)\n",
      "memory usage: 820.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           5000 non-null   object \n",
      " 1   Location       5000 non-null   object \n",
      " 2   MinTemp        4975 non-null   float64\n",
      " 3   MaxTemp        4993 non-null   float64\n",
      " 4   Rainfall       4955 non-null   float64\n",
      " 5   Evaporation    2853 non-null   float64\n",
      " 6   Sunshine       2612 non-null   float64\n",
      " 7   WindGustDir    4665 non-null   object \n",
      " 8   WindGustSpeed  4667 non-null   float64\n",
      " 9   WindDir9am     4608 non-null   object \n",
      " 10  WindDir3pm     4868 non-null   object \n",
      " 11  WindSpeed9am   4961 non-null   float64\n",
      " 12  WindSpeed3pm   4914 non-null   float64\n",
      " 13  Humidity9am    4943 non-null   float64\n",
      " 14  Humidity3pm    4882 non-null   float64\n",
      " 15  Pressure9am    4493 non-null   float64\n",
      " 16  Pressure3pm    4496 non-null   float64\n",
      " 17  Cloud9am       3103 non-null   float64\n",
      " 18  Cloud3pm       3009 non-null   float64\n",
      " 19  Temp9am        4976 non-null   float64\n",
      " 20  Temp3pm        4916 non-null   float64\n",
      " 21  RainToday      4955 non-null   object \n",
      " 22  RainTomorrow   5000 non-null   object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 898.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for data in DATA:\n",
    "    print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "col_trans = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, make_column_selector(dtype_include = np.number)),\n",
    "    ('cat_pipeline', cat_pipeline, make_column_selector(dtype_include = np.object_))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(),\n",
    "]\n",
    "\n",
    "pipelines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in classifiers:\n",
    "    pipelines.append((type(classifier), Pipeline([(\"transformer\", col_trans), (\"model\", classifier)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(sklearn.tree._classes.DecisionTreeClassifier,\n",
       "  Pipeline(steps=[('transformer',\n",
       "                   ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer()),\n",
       "                                                                    ('scale',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000280296D4250>),\n",
       "                                                   ('cat_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('one-hot',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x0000028029A74B50>)])),\n",
       "                  ('model', DecisionTreeClassifier())])),\n",
       " (sklearn.ensemble._forest.RandomForestClassifier,\n",
       "  Pipeline(steps=[('transformer',\n",
       "                   ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer()),\n",
       "                                                                    ('scale',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000280296D4250>),\n",
       "                                                   ('cat_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('one-hot',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x0000028029A74B50>)])),\n",
       "                  ('model', RandomForestClassifier())])),\n",
       " (xgboost.sklearn.XGBClassifier,\n",
       "  Pipeline(steps=[('transformer',\n",
       "                   ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer()),\n",
       "                                                                    ('scale',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000280296D4250>),\n",
       "                                                   ('cat_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('one-hot',\n",
       "                                                                     OneHotEncoder(handle_...\n",
       "                                 feature_types=None, gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None, learning_rate=None,\n",
       "                                 max_bin=None, max_cat_threshold=None,\n",
       "                                 max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                 max_depth=None, max_leaves=None,\n",
       "                                 min_child_weight=None, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=None, n_jobs=None,\n",
       "                                 num_parallel_tree=None, random_state=None, ...))]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe_score = []\n",
    "    for data in DATA:\n",
    "        score = cross_validate(pipe[1], data.iloc[:, :-1], LabelEncoder().fit_transform(data.iloc[:,-1]), cv = 5, scoring=\"accuracy\")\n",
    "        pipe_score.append(score[\"test_score\"].mean())\n",
    "\n",
    "    scores.append((pipe[0], pipe_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banking_final.csv',\n",
       " 'flights_final.csv',\n",
       " 'mushrooms_final.csv',\n",
       " 'weather_final.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(sklearn.tree._classes.DecisionTreeClassifier,\n",
       "  [0.8688, 0.9102, 0.9815999999999999, 0.791]),\n",
       " (sklearn.ensemble._forest.RandomForestClassifier,\n",
       "  [0.8998000000000002, 0.944, 0.9996, 0.8366]),\n",
       " (xgboost.sklearn.XGBClassifier,\n",
       "  [0.9016, 0.9469999999999998, 0.9974000000000001, 0.8368])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Searching - searching for new defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\macie\\OneDrive - Politechnika Warszawska\\Pulpit\\STUDIA\\SEMESTR5\\AutoML\\Projekty\\AutoML-project1\\automl1\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\macie\\OneDrive - Politechnika Warszawska\\Pulpit\\STUDIA\\SEMESTR5\\AutoML\\Projekty\\AutoML-project1\\automl1\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_distributions = [\n",
    "    {\n",
    "        \"model__max_depth\": randint(1,30),\n",
    "        \"model__min_samples_split\":randint(2,60),\n",
    "        \"model__criterion\":[\"gini\",\"entropy\"],\n",
    "        \"model__min_samples_leaf\":randint(1,60)\n",
    "    },\n",
    "    {\n",
    "        \"model__n_estimators\":randint(1,2000),\n",
    "        \"model__min_samples_leaf\":randint(1,5000),\n",
    "        \"model__min_samples_split\":randint(2,60),\n",
    "        \"model__max_features\":uniform(0,1)\n",
    "    },\n",
    "    {\n",
    "        \"model__max_depth\": randint(1,15),\n",
    "        \"model__min_child_weight\": randint(1,128),\n",
    "        \"model__eta\": uniform(0,1),\n",
    "        \"model__alpha\": uniform(2**(-10),2**(10))\n",
    "    }\n",
    "]\n",
    "best_params = [[],[],[],[]]\n",
    "pipe_best_models = []\n",
    "pipe_best_scores = []\n",
    "history = [[],[],[]]\n",
    "for i,pipe in enumerate(pipelines):    \n",
    "    for j,data in enumerate(DATA):\n",
    "        rs = RandomizedSearchCV(pipe[1], \n",
    "                                param_distributions= param_distributions[i],\n",
    "                                verbose=True,\n",
    "                                random_state=42,\n",
    "                                cv=5,\n",
    "                                n_iter=200\n",
    "                                )\n",
    "        rs.fit(data.iloc[:, :-1],LabelEncoder().fit_transform(data.iloc[:,-1]))\n",
    "        pipe_best_scores.append(rs.best_score_)\n",
    "        pipe_best_models.append(rs.best_estimator_)\n",
    "        best_params[j].append(rs.best_params_)\n",
    "        history[i].append(rs.cv_results_)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> shape: (800, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> shape: (800, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'> shape: (800, 18)\n"
     ]
    }
   ],
   "source": [
    "history_datasets = []\n",
    "for h in history:\n",
    "    df = pd.concat([pd.DataFrame(h[i]) for i in range(len(h))], keys=range(len(h)), names=['dataset'])\n",
    "    df = df.reset_index()\n",
    "    df.drop(columns='level_1', inplace=True)\n",
    "    history_datasets.append(df)\n",
    "print(f\"{pipelines[0][0]} shape: {history_datasets[0].shape}\")\n",
    "print(f\"{pipelines[1][0]} shape: {history_datasets[1].shape}\")\n",
    "print(f\"{pipelines[2][0]} shape: {history_datasets[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['DecisionTree','RandomForest','XGBoost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving history to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(history_datasets):\n",
    "    df.to_csv(f'../data/history_dataset_{model_names[i]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading history from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_DecisionTree = pd.read_csv('../data/history_dataset_DecisionTree.csv')\n",
    "history_RandomForest = pd.read_csv('../data/history_dataset_RandomForest.csv')\n",
    "history_XGBoost = pd.read_csv('../data/history_dataset_XGBoost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__criterion</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.028392</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>gini</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034022</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>entropy</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0       0.034176      0.006215         0.004794        0.002535   \n",
       "1        0       0.028392      0.001495         0.004094        0.002321   \n",
       "2        0       0.031333      0.001139         0.005442        0.002487   \n",
       "3        0       0.026831      0.003970         0.006345        0.003212   \n",
       "4        0       0.034022      0.001552         0.007549        0.001566   \n",
       "\n",
       "  param_model__criterion  param_model__max_depth  \\\n",
       "0                   gini                      20   \n",
       "1                   gini                       8   \n",
       "2                entropy                      19   \n",
       "3                   gini                      24   \n",
       "4                entropy                      24   \n",
       "\n",
       "   param_model__min_samples_leaf  param_model__min_samples_split  \\\n",
       "0                             29                              16   \n",
       "1                             21                              40   \n",
       "2                             23                              12   \n",
       "3                             53                              37   \n",
       "4                              3                              23   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__criterion': 'gini', 'model__max_depth...              0.902   \n",
       "1  {'model__criterion': 'gini', 'model__max_depth...              0.904   \n",
       "2  {'model__criterion': 'entropy', 'model__max_de...              0.889   \n",
       "3  {'model__criterion': 'gini', 'model__max_depth...              0.901   \n",
       "4  {'model__criterion': 'entropy', 'model__max_de...              0.887   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              0.894              0.891              0.884              0.886   \n",
       "1              0.889              0.885              0.887              0.889   \n",
       "2              0.898              0.895              0.890              0.874   \n",
       "3              0.903              0.891              0.896              0.891   \n",
       "4              0.890              0.872              0.881              0.870   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.8914        0.006375              121  \n",
       "1           0.8908        0.006765              134  \n",
       "2           0.8892        0.008280              151  \n",
       "3           0.8964        0.004964               24  \n",
       "4           0.8800        0.007925              200  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_DecisionTree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.640918</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.374540</td>\n",
       "      <td>861</td>\n",
       "      <td>16</td>\n",
       "      <td>1131</td>\n",
       "      <td>{'model__max_features': 0.3745401188473625, 'm...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.136891</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.779691</td>\n",
       "      <td>3093</td>\n",
       "      <td>40</td>\n",
       "      <td>122</td>\n",
       "      <td>{'model__max_features': 0.7796910002727693, 'm...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.101864</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>4427</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>{'model__max_features': 0.15599452033620265, '...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144345</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.333709</td>\n",
       "      <td>2920</td>\n",
       "      <td>25</td>\n",
       "      <td>131</td>\n",
       "      <td>{'model__max_features': 0.33370861113902184, '...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.595966</td>\n",
       "      <td>0.040971</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>770</td>\n",
       "      <td>25</td>\n",
       "      <td>1516</td>\n",
       "      <td>{'model__max_features': 0.020584494295802447, ...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0       1.640918      0.006159         0.049864        0.000418   \n",
       "1        0       0.136891      0.001464         0.009309        0.000396   \n",
       "2        0       0.101864      0.000262         0.008216        0.000592   \n",
       "3        0       0.144345      0.000598         0.009973        0.000584   \n",
       "4        0       1.595966      0.040971         0.062200        0.005089   \n",
       "\n",
       "   param_model__max_features  param_model__min_samples_leaf  \\\n",
       "0                   0.374540                            861   \n",
       "1                   0.779691                           3093   \n",
       "2                   0.155995                           4427   \n",
       "3                   0.333709                           2920   \n",
       "4                   0.020584                            770   \n",
       "\n",
       "   param_model__min_samples_split  param_model__n_estimators  \\\n",
       "0                              16                       1131   \n",
       "1                              40                        122   \n",
       "2                              12                         88   \n",
       "3                              25                        131   \n",
       "4                              25                       1516   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__max_features': 0.3745401188473625, 'm...              0.883   \n",
       "1  {'model__max_features': 0.7796910002727693, 'm...              0.883   \n",
       "2  {'model__max_features': 0.15599452033620265, '...              0.883   \n",
       "3  {'model__max_features': 0.33370861113902184, '...              0.883   \n",
       "4  {'model__max_features': 0.020584494295802447, ...              0.883   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              0.883              0.883              0.883              0.883   \n",
       "1              0.883              0.883              0.883              0.883   \n",
       "2              0.883              0.883              0.883              0.883   \n",
       "3              0.883              0.883              0.883              0.883   \n",
       "4              0.883              0.883              0.883              0.883   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.883             0.0                3  \n",
       "1            0.883             0.0                3  \n",
       "2            0.883             0.0                3  \n",
       "3            0.883             0.0                3  \n",
       "4            0.883             0.0                3  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_RandomForest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_child_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042777</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>383.530058</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>{'model__alpha': 383.5300582621992, 'model__et...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>613.027264</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>{'model__alpha': 613.0272643802655, 'model__et...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043707</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>59.478595</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>{'model__alpha': 59.47859542273625, 'model__et...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043490</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>725.067296</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>{'model__alpha': 725.0672962256506, 'model__et...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045204</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>852.422241</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>{'model__alpha': 852.4222407421319, 'model__et...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0       0.042777      0.001839         0.008124        0.000068   \n",
       "1        0       0.043513      0.000703         0.007536        0.000553   \n",
       "2        0       0.043707      0.001379         0.008389        0.000387   \n",
       "3        0       0.043490      0.000772         0.008100        0.000008   \n",
       "4        0       0.045204      0.001118         0.008311        0.000470   \n",
       "\n",
       "   param_model__alpha  param_model__eta  param_model__max_depth  \\\n",
       "0          383.530058          0.950714                      11   \n",
       "1          613.027264          0.156019                       3   \n",
       "2           59.478595          0.866176                       4   \n",
       "3          725.067296          0.020584                       2   \n",
       "4          852.422241          0.212339                      12   \n",
       "\n",
       "   param_model__min_child_weight  \\\n",
       "0                             72   \n",
       "1                             87   \n",
       "2                            104   \n",
       "3                             88   \n",
       "4                             21   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__alpha': 383.5300582621992, 'model__et...              0.883   \n",
       "1  {'model__alpha': 613.0272643802655, 'model__et...              0.883   \n",
       "2  {'model__alpha': 59.47859542273625, 'model__et...              0.883   \n",
       "3  {'model__alpha': 725.0672962256506, 'model__et...              0.883   \n",
       "4  {'model__alpha': 852.4222407421319, 'model__et...              0.883   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              0.883              0.883              0.883              0.883   \n",
       "1              0.883              0.883              0.883              0.883   \n",
       "2              0.883              0.883              0.883              0.883   \n",
       "3              0.883              0.883              0.883              0.883   \n",
       "4              0.883              0.883              0.883              0.883   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.883             0.0                7  \n",
       "1            0.883             0.0                7  \n",
       "2            0.883             0.0                7  \n",
       "3            0.883             0.0                7  \n",
       "4            0.883             0.0                7  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_XGBoost.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New defaults below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for DecisionTree: {'model__criterion': 'entropy', 'model__max_depth': 28, 'model__min_samples_leaf': 5, 'model__min_samples_split': 48}\n",
      "with score: 0.8935500000000001\n"
     ]
    }
   ],
   "source": [
    "df = history_DecisionTree\n",
    "df['params_str'] = df['params'].apply(lambda x: str(x))\n",
    "grouped_mean = df.groupby(['params_str'])['mean_test_score'].mean().reset_index()\n",
    "grouped_mean.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "best_params_DecisionTree = grouped_mean.iloc[0, 0]\n",
    "best_params_DecisionTree_score = grouped_mean.iloc[0, 1]\n",
    "print(f\"Best params for DecisionTree: {best_params_DecisionTree}\") \n",
    "print(f\"with score: {best_params_DecisionTree_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest: {'model__max_features': 0.9191765518355596, 'model__min_samples_leaf': 10, 'model__min_samples_split': 57, 'model__n_estimators': 798}\n",
      "with score: 0.90745\n"
     ]
    }
   ],
   "source": [
    "df = history_RandomForest\n",
    "df['params_str'] = df['params'].apply(lambda x: str(x))\n",
    "grouped_mean = df.groupby(['params_str'])['mean_test_score'].mean().reset_index()\n",
    "grouped_mean.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "best_params_RandomForest = grouped_mean.iloc[0, 0]\n",
    "best_params_RandomForest_score = grouped_mean.iloc[0, 1]\n",
    "print(f\"Best params for RandomForest: {best_params_RandomForest}\") \n",
    "print(f\"with score: {best_params_RandomForest_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'model__alpha': 14.73990891937001, 'model__eta': 0.11607264050691624, 'model__max_depth': 5, 'model__min_child_weight': 47}\n",
      "With score: 0.88395\n"
     ]
    }
   ],
   "source": [
    "df = history_XGBoost\n",
    "df['params_str'] = df['params'].apply(lambda x: str(x))\n",
    "grouped_mean = df.groupby(['params_str'])['mean_test_score'].mean().reset_index()\n",
    "grouped_mean.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "best_params_XGBoost = grouped_mean.iloc[0, 0]\n",
    "best_params_XGBoost_score = grouped_mean.iloc[0, 1]\n",
    "print(f\"Best params for XGBoost: {best_params_XGBoost}\")\n",
    "print(f\"With score: {best_params_XGBoost_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
