{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "DATA = []\n",
    "for file in os.listdir(data_path):\n",
    "    DATA.append(pd.read_csv(os.path.join(data_path,file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        5000 non-null   int64 \n",
      " 1   job        5000 non-null   object\n",
      " 2   marital    5000 non-null   object\n",
      " 3   education  5000 non-null   object\n",
      " 4   default    5000 non-null   object\n",
      " 5   balance    5000 non-null   int64 \n",
      " 6   housing    5000 non-null   object\n",
      " 7   loan       5000 non-null   object\n",
      " 8   contact    5000 non-null   object\n",
      " 9   day        5000 non-null   int64 \n",
      " 10  month      5000 non-null   object\n",
      " 11  duration   5000 non-null   int64 \n",
      " 12  campaign   5000 non-null   int64 \n",
      " 13  pdays      5000 non-null   int64 \n",
      " 14  previous   5000 non-null   int64 \n",
      " 15  poutcome   5000 non-null   object\n",
      " 16  y          5000 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 664.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Unnamed: 0                         5000 non-null   int64  \n",
      " 1   id                                 5000 non-null   int64  \n",
      " 2   Gender                             5000 non-null   object \n",
      " 3   Customer Type                      5000 non-null   object \n",
      " 4   Age                                5000 non-null   int64  \n",
      " 5   Type of Travel                     5000 non-null   object \n",
      " 6   Class                              5000 non-null   object \n",
      " 7   Flight Distance                    5000 non-null   int64  \n",
      " 8   Inflight wifi service              5000 non-null   int64  \n",
      " 9   Departure/Arrival time convenient  5000 non-null   int64  \n",
      " 10  Ease of Online booking             5000 non-null   int64  \n",
      " 11  Gate location                      5000 non-null   int64  \n",
      " 12  Food and drink                     5000 non-null   int64  \n",
      " 13  Online boarding                    5000 non-null   int64  \n",
      " 14  Seat comfort                       5000 non-null   int64  \n",
      " 15  Inflight entertainment             5000 non-null   int64  \n",
      " 16  On-board service                   5000 non-null   int64  \n",
      " 17  Leg room service                   5000 non-null   int64  \n",
      " 18  Baggage handling                   5000 non-null   int64  \n",
      " 19  Checkin service                    5000 non-null   int64  \n",
      " 20  Inflight service                   5000 non-null   int64  \n",
      " 21  Cleanliness                        5000 non-null   int64  \n",
      " 22  Departure Delay in Minutes         5000 non-null   int64  \n",
      " 23  Arrival Delay in Minutes           4981 non-null   float64\n",
      " 24  satisfaction                       5000 non-null   object \n",
      "dtypes: float64(1), int64(19), object(5)\n",
      "memory usage: 976.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   season                5000 non-null   object \n",
      " 1   cap-diameter          5000 non-null   float64\n",
      " 2   cap-shape             5000 non-null   object \n",
      " 3   cap-surface           3839 non-null   object \n",
      " 4   cap-color             5000 non-null   object \n",
      " 5   does-bruise-or-bleed  5000 non-null   object \n",
      " 6   gill-attachment       4215 non-null   object \n",
      " 7   gill-spacing          2992 non-null   object \n",
      " 8   gill-color            5000 non-null   object \n",
      " 9   stem-height           5000 non-null   float64\n",
      " 10  stem-width            5000 non-null   float64\n",
      " 11  stem-root             747 non-null    object \n",
      " 12  stem-surface          1934 non-null   object \n",
      " 13  stem-color            5000 non-null   object \n",
      " 14  veil-type             258 non-null    object \n",
      " 15  veil-color            578 non-null    object \n",
      " 16  has-ring              5000 non-null   object \n",
      " 17  ring-type             4784 non-null   object \n",
      " 18  spore-print-color     513 non-null    object \n",
      " 19  habitat               5000 non-null   object \n",
      " 20  class                 5000 non-null   object \n",
      "dtypes: float64(3), object(18)\n",
      "memory usage: 820.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           5000 non-null   object \n",
      " 1   Location       5000 non-null   object \n",
      " 2   MinTemp        4975 non-null   float64\n",
      " 3   MaxTemp        4993 non-null   float64\n",
      " 4   Rainfall       4955 non-null   float64\n",
      " 5   Evaporation    2853 non-null   float64\n",
      " 6   Sunshine       2612 non-null   float64\n",
      " 7   WindGustDir    4665 non-null   object \n",
      " 8   WindGustSpeed  4667 non-null   float64\n",
      " 9   WindDir9am     4608 non-null   object \n",
      " 10  WindDir3pm     4868 non-null   object \n",
      " 11  WindSpeed9am   4961 non-null   float64\n",
      " 12  WindSpeed3pm   4914 non-null   float64\n",
      " 13  Humidity9am    4943 non-null   float64\n",
      " 14  Humidity3pm    4882 non-null   float64\n",
      " 15  Pressure9am    4493 non-null   float64\n",
      " 16  Pressure3pm    4496 non-null   float64\n",
      " 17  Cloud9am       3103 non-null   float64\n",
      " 18  Cloud3pm       3009 non-null   float64\n",
      " 19  Temp9am        4976 non-null   float64\n",
      " 20  Temp3pm        4916 non-null   float64\n",
      " 21  RainToday      4955 non-null   object \n",
      " 22  RainTomorrow   5000 non-null   object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 898.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for data in DATA:\n",
    "    print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "col_trans = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, make_column_selector(dtype_include = np.number)),\n",
    "    ('cat_pipeline', cat_pipeline, make_column_selector(dtype_include = np.object_))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(),\n",
    "]\n",
    "\n",
    "pipelines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in classifiers:\n",
    "    pipelines.append((type(classifier), Pipeline([(\"transformer\", col_trans), (\"model\", classifier)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(sklearn.tree._classes.DecisionTreeClassifier,\n",
       "  Pipeline(steps=[('transformer',\n",
       "                   ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer()),\n",
       "                                                                    ('scale',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000258CF2D4250>),\n",
       "                                                   ('cat_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('one-hot',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000258CE4AF090>)])),\n",
       "                  ('model', DecisionTreeClassifier())])),\n",
       " (sklearn.ensemble._forest.RandomForestClassifier,\n",
       "  Pipeline(steps=[('transformer',\n",
       "                   ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer()),\n",
       "                                                                    ('scale',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000258CF2D4250>),\n",
       "                                                   ('cat_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('one-hot',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000258CE4AF090>)])),\n",
       "                  ('model', RandomForestClassifier())])),\n",
       " (xgboost.sklearn.XGBClassifier,\n",
       "  Pipeline(steps=[('transformer',\n",
       "                   ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer()),\n",
       "                                                                    ('scale',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000258CF2D4250>),\n",
       "                                                   ('cat_pipeline',\n",
       "                                                    Pipeline(steps=[('impute',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('one-hot',\n",
       "                                                                     OneHotEncoder(handle_...\n",
       "                                 feature_types=None, gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None, learning_rate=None,\n",
       "                                 max_bin=None, max_cat_threshold=None,\n",
       "                                 max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                 max_depth=None, max_leaves=None,\n",
       "                                 min_child_weight=None, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=None, n_jobs=None,\n",
       "                                 num_parallel_tree=None, random_state=None, ...))]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe_score = []\n",
    "    for data in DATA:\n",
    "        score = cross_validate(pipe[1], data.iloc[:, :-1], LabelEncoder().fit_transform(data.iloc[:,-1]), cv = 5, scoring=\"accuracy\")\n",
    "        pipe_score.append(score[\"test_score\"].mean())\n",
    "\n",
    "    scores.append((pipe[0], pipe_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banking_final.csv',\n",
       " 'flights_final.csv',\n",
       " 'mushrooms_final.csv',\n",
       " 'weather_final.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(sklearn.tree._classes.DecisionTreeClassifier,\n",
       "  [0.8671999999999999, 0.913, 0.9795999999999999, 0.7896000000000001]),\n",
       " (sklearn.ensemble._forest.RandomForestClassifier,\n",
       "  [0.8998000000000002, 0.9409999999999998, 0.9991999999999999, 0.8336]),\n",
       " (xgboost.sklearn.XGBClassifier,\n",
       "  [0.9016, 0.9469999999999998, 0.9974000000000001, 0.8368])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Searching - searching for new defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\macie\\OneDrive - Politechnika Warszawska\\Pulpit\\STUDIA\\SEMESTR5\\AutoML\\Projekty\\AutoML-project1\\automl1\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_distributions = [\n",
    "    {\n",
    "        \"model__max_depth\": randint(1,31),\n",
    "        \"model__min_samples_split\":randint(2,61),\n",
    "        \"model__min_impurity_decrease\":uniform(0,1),\n",
    "        \"model__min_samples_leaf\":randint(1,61)\n",
    "    },\n",
    "    {\n",
    "        \"model__n_estimators\":randint(1,2001),\n",
    "        \"model__min_samples_leaf\":randint(1,5001),\n",
    "        \"model__max_samples\":uniform(0.1,0.9),\n",
    "        \"model__max_features\":uniform(0,1)\n",
    "    },\n",
    "    {\n",
    "        \"model__max_depth\": randint(1,16),\n",
    "        \"model__min_child_weight\": randint(1,129),\n",
    "        \"model__eta\": uniform(2**(-10),1-2**(-10)),\n",
    "        \"model__alpha\": uniform(2**(-10),2**(10))\n",
    "    }\n",
    "]\n",
    "\n",
    "best_params = [[],[],[],[]]\n",
    "pipe_best_models = []\n",
    "pipe_best_scores = []\n",
    "history = [[],[],[]]\n",
    "for i,pipe in enumerate(pipelines):    \n",
    "    for j,data in enumerate(DATA):\n",
    "        rs = RandomizedSearchCV(pipe[1], \n",
    "                                param_distributions= param_distributions[i],\n",
    "                                verbose=True,\n",
    "                                random_state=42,\n",
    "                                cv=5,\n",
    "                                n_iter=200,\n",
    "                                n_jobs=-1,\n",
    "                                scoring=\"roc_auc\"\n",
    "                                )\n",
    "        rs.fit(data.iloc[:, :-1],LabelEncoder().fit_transform(data.iloc[:,-1]))\n",
    "        pipe_best_scores.append(rs.best_score_)\n",
    "        pipe_best_models.append(rs.best_estimator_)\n",
    "        best_params[j].append(rs.best_params_)\n",
    "        history[i].append(rs.cv_results_)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> shape: (800, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> shape: (800, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'> shape: (800, 18)\n"
     ]
    }
   ],
   "source": [
    "history_datasets = []\n",
    "for h in history:\n",
    "    df = pd.concat([pd.DataFrame(h[i]) for i in range(len(h))], keys=range(len(h)), names=['dataset'])\n",
    "    df = df.reset_index()\n",
    "    df.drop(columns='level_1', inplace=True)\n",
    "    history_datasets.append(df)\n",
    "print(f\"{pipelines[0][0]} shape: {history_datasets[0].shape}\")\n",
    "print(f\"{pipelines[1][0]} shape: {history_datasets[1].shape}\")\n",
    "print(f\"{pipelines[2][0]} shape: {history_datasets[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['DecisionTree','RandomForest','XGBoost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving history to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(history_datasets):\n",
    "    df.to_csv(f'../history/history_dataset_{model_names[i]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading history from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_DecisionTree = pd.read_csv('../history/history_dataset_DecisionTree.csv')\n",
    "history_RandomForest = pd.read_csv('../history/history_dataset_RandomForest.csv')\n",
    "history_XGBoost = pd.read_csv('../history/history_dataset_XGBoost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_impurity_decrease</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045820</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>7</td>\n",
       "      <td>0.796543</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>{'model__max_depth': 7, 'model__min_impurity_d...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.049378</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>8</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>{'model__max_depth': 8, 'model__min_impurity_d...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058931</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>19</td>\n",
       "      <td>0.099975</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>{'model__max_depth': 19, 'model__min_impurity_...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.047674</td>\n",
       "      <td>0.013412</td>\n",
       "      <td>0.012412</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>21</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__max_depth': 21, 'model__min_impurity_...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048580</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>22</td>\n",
       "      <td>0.056412</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>{'model__max_depth': 22, 'model__min_impurity_...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0       0.045820      0.002683         0.014951        0.001641   \n",
       "1        0       0.049378      0.009177         0.016595        0.008528   \n",
       "2        0       0.058931      0.009848         0.009868        0.002243   \n",
       "3        0       0.047674      0.013412         0.012412        0.003954   \n",
       "4        0       0.048580      0.012482         0.013218        0.004257   \n",
       "\n",
       "   param_model__max_depth  param_model__min_impurity_decrease  \\\n",
       "0                       7                            0.796543   \n",
       "1                       8                            0.598658   \n",
       "2                      19                            0.099975   \n",
       "3                      21                            0.601115   \n",
       "4                      22                            0.056412   \n",
       "\n",
       "   param_model__min_samples_leaf  param_model__min_samples_split  \\\n",
       "0                             15                              44   \n",
       "1                             39                              59   \n",
       "2                             11                              25   \n",
       "3                             24                               4   \n",
       "4                             24                              45   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__max_depth': 7, 'model__min_impurity_d...                0.5   \n",
       "1  {'model__max_depth': 8, 'model__min_impurity_d...                0.5   \n",
       "2  {'model__max_depth': 19, 'model__min_impurity_...                0.5   \n",
       "3  {'model__max_depth': 21, 'model__min_impurity_...                0.5   \n",
       "4  {'model__max_depth': 22, 'model__min_impurity_...                0.5   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                0.5                0.5                0.5                0.5   \n",
       "1                0.5                0.5                0.5                0.5   \n",
       "2                0.5                0.5                0.5                0.5   \n",
       "3                0.5                0.5                0.5                0.5   \n",
       "4                0.5                0.5                0.5                0.5   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.5             0.0                7  \n",
       "1              0.5             0.0                7  \n",
       "2              0.5             0.0                7  \n",
       "3              0.5             0.0                7  \n",
       "4              0.5             0.0                7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_DecisionTree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_DecisionTree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__max_samples</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.430337</td>\n",
       "      <td>0.085638</td>\n",
       "      <td>0.093527</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.955643</td>\n",
       "      <td>3773</td>\n",
       "      <td>1045</td>\n",
       "      <td>{'model__max_features': 0.3745401188473625, 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.906768</td>\n",
       "      <td>0.849372</td>\n",
       "      <td>0.148279</td>\n",
       "      <td>0.031769</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.240395</td>\n",
       "      <td>4427</td>\n",
       "      <td>1483</td>\n",
       "      <td>{'model__max_features': 0.15601864044243652, '...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16.546819</td>\n",
       "      <td>2.208717</td>\n",
       "      <td>0.250995</td>\n",
       "      <td>0.033240</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.641004</td>\n",
       "      <td>131</td>\n",
       "      <td>1686</td>\n",
       "      <td>{'model__max_features': 0.8661761457749352, 'm...</td>\n",
       "      <td>0.880381</td>\n",
       "      <td>0.867381</td>\n",
       "      <td>0.873324</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.860107</td>\n",
       "      <td>0.862968</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.203614</td>\n",
       "      <td>0.641014</td>\n",
       "      <td>0.135754</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.056412</td>\n",
       "      <td>0.749799</td>\n",
       "      <td>2434</td>\n",
       "      <td>1216</td>\n",
       "      <td>{'model__max_features': 0.056411579027100256, ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.992212</td>\n",
       "      <td>0.655733</td>\n",
       "      <td>3386</td>\n",
       "      <td>22</td>\n",
       "      <td>{'model__max_features': 0.9922115592912175, 'm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0       2.430337      0.085638         0.093527        0.002885   \n",
       "1        0       3.906768      0.849372         0.148279        0.031769   \n",
       "2        0      16.546819      2.208717         0.250995        0.033240   \n",
       "3        0       3.203614      0.641014         0.135754        0.049218   \n",
       "4        0       0.095550      0.007481         0.016689        0.003296   \n",
       "\n",
       "   param_model__max_features  param_model__max_samples  \\\n",
       "0                   0.374540                  0.955643   \n",
       "1                   0.156019                  0.240395   \n",
       "2                   0.866176                  0.641004   \n",
       "3                   0.056412                  0.749799   \n",
       "4                   0.992212                  0.655733   \n",
       "\n",
       "   param_model__min_samples_leaf  param_model__n_estimators  \\\n",
       "0                           3773                       1045   \n",
       "1                           4427                       1483   \n",
       "2                            131                       1686   \n",
       "3                           2434                       1216   \n",
       "4                           3386                         22   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__max_features': 0.3745401188473625, 'm...           0.500000   \n",
       "1  {'model__max_features': 0.15601864044243652, '...           0.500000   \n",
       "2  {'model__max_features': 0.8661761457749352, 'm...           0.880381   \n",
       "3  {'model__max_features': 0.056411579027100256, ...           0.500000   \n",
       "4  {'model__max_features': 0.9922115592912175, 'm...           0.500000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.500000           0.500000           0.500000           0.500000   \n",
       "1           0.500000           0.500000           0.500000           0.500000   \n",
       "2           0.867381           0.873324           0.833648           0.860107   \n",
       "3           0.500000           0.500000           0.500000           0.500000   \n",
       "4           0.500000           0.500000           0.500000           0.500000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.500000        0.000000               25  \n",
       "1         0.500000        0.000000               25  \n",
       "2         0.862968        0.016111                2  \n",
       "3         0.500000        0.000000               25  \n",
       "4         0.500000        0.000000               25  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_RandomForest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_child_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.120718</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.015755</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>383.530058</td>\n",
       "      <td>0.950762</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>{'model__alpha': 383.5300582621992, 'model__et...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.130825</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.021409</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>613.027264</td>\n",
       "      <td>0.156843</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>{'model__alpha': 613.0272643802655, 'model__et...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.158108</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>59.478595</td>\n",
       "      <td>0.866307</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>{'model__alpha': 59.47859542273625, 'model__et...</td>\n",
       "      <td>0.840699</td>\n",
       "      <td>0.839393</td>\n",
       "      <td>0.830057</td>\n",
       "      <td>0.802664</td>\n",
       "      <td>0.842297</td>\n",
       "      <td>0.831022</td>\n",
       "      <td>0.014805</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.117092</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.014069</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>725.067296</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>{'model__alpha': 725.0672962256506, 'model__et...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113698</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>852.422241</td>\n",
       "      <td>0.213108</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>{'model__alpha': 852.4222407421319, 'model__et...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0       0.120718      0.009384         0.015755        0.004705   \n",
       "1        0       0.130825      0.014063         0.021409        0.013045   \n",
       "2        0       0.158108      0.035043         0.017295        0.002255   \n",
       "3        0       0.117092      0.014543         0.014069        0.002245   \n",
       "4        0       0.113698      0.008851         0.015426        0.002006   \n",
       "\n",
       "   param_model__alpha  param_model__eta  param_model__max_depth  \\\n",
       "0          383.530058          0.950762                      11   \n",
       "1          613.027264          0.156843                       3   \n",
       "2           59.478595          0.866307                       4   \n",
       "3          725.067296          0.021541                       2   \n",
       "4          852.422241          0.213108                      12   \n",
       "\n",
       "   param_model__min_child_weight  \\\n",
       "0                             72   \n",
       "1                             87   \n",
       "2                            104   \n",
       "3                             88   \n",
       "4                             21   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__alpha': 383.5300582621992, 'model__et...           0.500000   \n",
       "1  {'model__alpha': 613.0272643802655, 'model__et...           0.500000   \n",
       "2  {'model__alpha': 59.47859542273625, 'model__et...           0.840699   \n",
       "3  {'model__alpha': 725.0672962256506, 'model__et...           0.500000   \n",
       "4  {'model__alpha': 852.4222407421319, 'model__et...           0.500000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.500000           0.500000           0.500000           0.500000   \n",
       "1           0.500000           0.500000           0.500000           0.500000   \n",
       "2           0.839393           0.830057           0.802664           0.842297   \n",
       "3           0.500000           0.500000           0.500000           0.500000   \n",
       "4           0.500000           0.500000           0.500000           0.500000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.500000        0.000000               72  \n",
       "1         0.500000        0.000000               72  \n",
       "2         0.831022        0.014805               19  \n",
       "3         0.500000        0.000000               72  \n",
       "4         0.500000        0.000000               72  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_XGBoost.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New defaults below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_overall(df):\n",
    "    df['params_str'] = df['params'].apply(lambda x: str(x))\n",
    "    grouped_mean = df.groupby(['params_str'])['mean_test_score'].mean().reset_index()\n",
    "    grouped_mean.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "    return grouped_mean.iloc[0, 0], grouped_mean.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for DecisionTree: {'model__max_depth': 25, 'model__min_impurity_decrease': 0.005061583846218687, 'model__min_samples_leaf': 46, 'model__min_samples_split': 19}\n",
      "with score: 0.829105606507877\n"
     ]
    }
   ],
   "source": [
    "best_params_DecisionTree, best_params_DecisionTree_score = get_best_params_overall(history_DecisionTree)\n",
    "print(f\"Best params for DecisionTree: {best_params_DecisionTree}\") \n",
    "print(f\"with score: {best_params_DecisionTree_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest: {'model__max_features': 0.02431596643145384, 'model__max_samples': 0.680925066316451, 'model__min_samples_leaf': 17, 'model__n_estimators': 1196}\n",
      "with score: 0.8965365914913082\n"
     ]
    }
   ],
   "source": [
    "best_params_RandomForest, best_params_RandomForest_score = get_best_params_overall(history_RandomForest)\n",
    "print(f\"Best params for RandomForest: {best_params_RandomForest}\") \n",
    "print(f\"with score: {best_params_RandomForest_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'model__alpha': 14.418715022746483, 'model__eta': 0.1996247845535622, 'model__max_depth': 8, 'model__min_child_weight': 35}\n",
      "With score: 0.9250081472612419\n"
     ]
    }
   ],
   "source": [
    "best_params_XGBoost, best_params_XGBoost_score = get_best_params_overall(history_XGBoost)\n",
    "print(f\"Best params for XGBoost: {best_params_XGBoost}\")\n",
    "print(f\"With score: {best_params_XGBoost_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's compute tunability of each of the ML algorithms. We'll start with looking for the optimal configuration of the hyperparameters for each of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_per_dataset(df):\n",
    "    df['params_str'] = df['params'].apply(lambda x: str(x))\n",
    "    best_params_per_dataset = df.sort_values(['dataset', 'rank_test_score'], ascending=[True, True]).groupby('dataset').first().reset_index()\n",
    "    best_params_per_dataset.rename(columns={'params_str': 'best_params', 'mean_test_score': 'best_score'}, inplace=True)\n",
    "    best_params_per_dataset = best_params_per_dataset[['dataset', 'best_params', 'best_score']]\n",
    "    default_params, _ = get_best_params_overall(df)\n",
    "    score_for_default_params = df[df['params_str'] == default_params][['dataset', 'mean_test_score']].rename(columns={'mean_test_score': 'default_score'})\n",
    "    best_params_per_dataset = best_params_per_dataset.merge(score_for_default_params, on='dataset', how='left')\n",
    "    best_params_per_dataset['abs_tunability'] = best_params_per_dataset['best_score'] - best_params_per_dataset['default_score']\n",
    "    best_params_per_dataset['rel_tunability (%)'] = best_params_per_dataset['abs_tunability'] / best_params_per_dataset['default_score'] * 100 \n",
    "    return best_params_per_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>default_score</th>\n",
       "      <th>abs_tunability</th>\n",
       "      <th>rel_tunability (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'model__max_depth': 25, 'model__min_impurity_...</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model__max_depth': 25, 'model__min_impurity_...</td>\n",
       "      <td>0.934547</td>\n",
       "      <td>0.934547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'model__max_depth': 25, 'model__min_impurity_...</td>\n",
       "      <td>0.855210</td>\n",
       "      <td>0.855210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'model__max_depth': 25, 'model__min_impurity_...</td>\n",
       "      <td>0.751481</td>\n",
       "      <td>0.751481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                                        best_params  best_score  \\\n",
       "0        0  {'model__max_depth': 25, 'model__min_impurity_...    0.775184   \n",
       "1        1  {'model__max_depth': 25, 'model__min_impurity_...    0.934547   \n",
       "2        2  {'model__max_depth': 25, 'model__min_impurity_...    0.855210   \n",
       "3        3  {'model__max_depth': 25, 'model__min_impurity_...    0.751481   \n",
       "\n",
       "   default_score  abs_tunability  rel_tunability (%)  \n",
       "0       0.775184             0.0                 0.0  \n",
       "1       0.934547             0.0                 0.0  \n",
       "2       0.855210             0.0                 0.0  \n",
       "3       0.751481             0.0                 0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_per_dataset_DecisionTree = get_best_params_per_dataset(history_DecisionTree)\n",
    "best_params_per_dataset_DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>default_score</th>\n",
       "      <th>abs_tunability</th>\n",
       "      <th>rel_tunability (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'model__max_features': 0.02431596643145384, '...</td>\n",
       "      <td>0.866173</td>\n",
       "      <td>0.866173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model__max_features': 0.02431596643145384, '...</td>\n",
       "      <td>0.957959</td>\n",
       "      <td>0.957959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'model__max_features': 0.02431596643145384, '...</td>\n",
       "      <td>0.938172</td>\n",
       "      <td>0.938172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'model__max_features': 0.8661761457749352, 'm...</td>\n",
       "      <td>0.828975</td>\n",
       "      <td>0.823842</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.623063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                                        best_params  best_score  \\\n",
       "0        0  {'model__max_features': 0.02431596643145384, '...    0.866173   \n",
       "1        1  {'model__max_features': 0.02431596643145384, '...    0.957959   \n",
       "2        2  {'model__max_features': 0.02431596643145384, '...    0.938172   \n",
       "3        3  {'model__max_features': 0.8661761457749352, 'm...    0.828975   \n",
       "\n",
       "   default_score  abs_tunability  rel_tunability (%)  \n",
       "0       0.866173        0.000000            0.000000  \n",
       "1       0.957959        0.000000            0.000000  \n",
       "2       0.938172        0.000000            0.000000  \n",
       "3       0.823842        0.005133            0.623063  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_per_dataset_RandomForest = get_best_params_per_dataset(history_RandomForest)\n",
    "best_params_per_dataset_RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>default_score</th>\n",
       "      <th>abs_tunability</th>\n",
       "      <th>rel_tunability (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'model__alpha': 14.418715022746483, 'model__e...</td>\n",
       "      <td>0.892356</td>\n",
       "      <td>0.892356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 14.418715022746483, 'model__e...</td>\n",
       "      <td>0.977244</td>\n",
       "      <td>0.977244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'model__alpha': 14.418715022746483, 'model__e...</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'model__alpha': 14.73990891937001, 'model__et...</td>\n",
       "      <td>0.845808</td>\n",
       "      <td>0.845485</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.038144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                                        best_params  best_score  \\\n",
       "0        0  {'model__alpha': 14.418715022746483, 'model__e...    0.892356   \n",
       "1        1  {'model__alpha': 14.418715022746483, 'model__e...    0.977244   \n",
       "2        2  {'model__alpha': 14.418715022746483, 'model__e...    0.984947   \n",
       "3        3  {'model__alpha': 14.73990891937001, 'model__et...    0.845808   \n",
       "\n",
       "   default_score  abs_tunability  rel_tunability (%)  \n",
       "0       0.892356        0.000000            0.000000  \n",
       "1       0.977244        0.000000            0.000000  \n",
       "2       0.984947        0.000000            0.000000  \n",
       "3       0.845485        0.000323            0.038144  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_per_dataset_XGBoost = get_best_params_per_dataset(history_XGBoost)\n",
    "best_params_per_dataset_XGBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
